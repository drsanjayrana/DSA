{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation for non-agricultural land covers based on U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initliasations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy for numerical processing and arrays\n",
    "import numpy as np\n",
    "\n",
    "# Useful python libaries for manipulating data\n",
    "import pickle\n",
    "import itertools\n",
    "import glob\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas to bring dataframe structure\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geospatial libraries to handle georeferenced raster and vector data\n",
    "import fiona\n",
    "from fiona import collection\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, mapping, shape\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio import windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib for data plotting\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit learn and scikit image libraries for machine learning and computer vision tools.\n",
    "from skimage import io, exposure, measure\n",
    "from sklearn.metrics import jaccard_similarity_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# Keras deep learning library\n",
    "import keras\n",
    "from keras.models import load_model, Model\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializse a random number generator to ensure results are reproducible\n",
    "np.random.seed(7)\n",
    "# turn warnig off\n",
    "np.warnings.filterwarnings('ignore')\n",
    "# print floating points as using fixed point notation i.e. not scientific\n",
    "np.set_printoptions(suppress=True)\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells to run after file export\n",
    "# set some useful paths\n",
    "# RAW INPUTS\n",
    "root = '/Volumes/NewVolume/DSA/Classify_LandCover/'\n",
    "ap_rgb_train_dir = os.path.join(root, 'DATA/AP_RGB_TRAIN')  # full res input RGB AP for training\n",
    "ap_rgb_test_dir = os.path.join(root, 'DATA/AP_RGB_TEST')  # full res input RGB AP for testing\n",
    "\n",
    "labels_dir = os.path.join(root, 'DATA/LABELS')  # land cover polygons after generalisation\n",
    "\n",
    "# DERIVED INPUTS\n",
    "image_chips_dir = os.path.join(root, 'DATA/IMAGE_CHIPS/RGB')  # pre-procssed image tiles and mask root folder\n",
    "model_dir = os.path.join(root, 'MODELS/RGB')  # contains the machine learning models\n",
    "predictions_dir = os.path.join(root, 'PREDICTIONS/UNET/RGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function by cate to create 3D tiles \n",
    "def get_tile_images(arr, newshape):\n",
    "    oldshape = np.array(arr.shape)\n",
    "    repeats = (oldshape / newshape).astype(int)\n",
    "    tmpshape = np.column_stack([repeats, newshape]).ravel()\n",
    "    order = np.arange(len(tmpshape))\n",
    "    order = np.concatenate([order[::2], order[1::2]])\n",
    "    #pdb.set_trace()\n",
    "    # newshape must divide oldshape evenly or else ValueError will be raised\n",
    "    return arr.reshape(tmpshape).transpose(order).reshape(-1, *newshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first 3 bands from 4-band RGBA\n",
    "# extract the first band (NIR) from 3-band CIR\n",
    "# resample the NIR band to 25cm\n",
    "# append the NIR band  onto the RGB image\n",
    "# append the slope image\n",
    "\n",
    "def resizeImage(RGB_ImageName, tileYSize, tileXSize):\n",
    "    with rasterio.open(RGB_ImageName) as rgb_src:\n",
    "        newHeight = int(rgb_src.height / tileYSize) * tileYSize\n",
    "        newWidth = int(rgb_src.height / tileXSize) * tileXSize\n",
    "        # only read image upto size  to which tiling can be done into 256x256 blocks\n",
    "        # numpy.ndarray - read the first three bands as the last band is alpha\n",
    "        rgb_image = rgb_src.read([1, 2, 3], window=((0, newWidth), (0, newHeight)))\n",
    "        # show(rgb_image)\n",
    "        out_metadata = rgb_src.meta.copy()\n",
    "        out_transform = rgb_src.transform            \n",
    "\n",
    "    return rgb_image, out_metadata, out_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepImages(ap_rgb_train_dir,image_chips_dir,allPolygons):\n",
    "    # read the rgb that we have and store them in a dictionary\n",
    "    rgb_list = {}\n",
    "    for filename in os.listdir(ap_rgb_train_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            # get os1k tile name\n",
    "            os1k_tile = filename[:6]\n",
    "            if os1k_tile in rgb_list:\n",
    "                print(os1k_tile + 'already exists so summin wrong?!')\n",
    "                continue\n",
    "            else:\n",
    "                rgb_list[os1k_tile]= os.path.join(ap_rgb_train_dir, filename)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    if len(rgb_list) < 1:\n",
    "        raise ValueError('RGB list is empty')\n",
    "    \n",
    "    # iterate through the RGB \n",
    "    # create image chips\n",
    "    for os1k_tile in rgb_list:\n",
    "        rgb_image_name = rgb_list[os1k_tile]\n",
    "        rgb_image, inputMetadata, inputTransform = resizeImage(rgb_image_name,256,256)\n",
    "        \n",
    "        # Affine(0.25,0.0,462000.0,0.0,-0.25,372000.0)\n",
    "        ULX = inputTransform.c\n",
    "        ULY = inputTransform.f\n",
    "        cellSizeX = inputTransform.a\n",
    "        cellSizeY = inputTransform.e\n",
    "\n",
    "        # make tiles\n",
    "        rgb_image_tiled = get_tile_images(rgb_image,(3,256,256))\n",
    "     \n",
    "        # write image chips\n",
    "        numtiles,numbands,rows,cols = rgb_image_tiled.shape\n",
    "        rowOffset = 0\n",
    "        blockSize = int(math.sqrt(numtiles))\n",
    "        for tileIndexAlongY in range(0,blockSize):\n",
    "            tileULY = ULY + (tileIndexAlongY * cellSizeY * 256)\n",
    "            for tileIndexAlongX in range(0,blockSize):\n",
    "                tileULX = ULX + (tileIndexAlongX * cellSizeX * 256)\n",
    "                # print(str(tileULX)+\",\"+str(tileULY))\n",
    "                globalTileIndex = tileIndexAlongY + tileIndexAlongX + rowOffset\n",
    "                aTileImage = rgb_image_tiled[globalTileIndex,:,:,:]              \n",
    "                    \n",
    "                # aTileImage = np.expand_dims(aTileImage,0)\n",
    "                tileMetadata = inputMetadata.copy()\n",
    "                tileTransform = Affine(cellSizeX,\n",
    "                                   inputTransform.b,\n",
    "                                   tileULX,\n",
    "                                   inputTransform.d,\n",
    "                                   cellSizeY,\n",
    "                                   tileULY)\n",
    "                               \n",
    "                tileMetadata.update({'driver': 'GTiff',\n",
    "                                 'dtype': 'uint8',\n",
    "                                 'count': 3,\n",
    "                                 'height': 256,\n",
    "                                 'width': 256,\n",
    "                                 'transform': tileTransform,\n",
    "                                 'nodata':0})\n",
    "                \n",
    "                tileFileName = os.path.basename(rgb_image_name).replace(\".tif\",\"_\"+str(globalTileIndex).zfill(4)+\".tif\")\n",
    "                tileFullName = os.path.join(image_chips_dir, tileFileName)\n",
    "                with rasterio.open(tileFullName, 'w', **tileMetadata) as dest:\n",
    "                    dest.write(aTileImage)\n",
    "                \n",
    "                #now mask nodata areas in the image\n",
    "                maskDone = maskImage(tileFullName,allPolygons)\n",
    "                if (not maskDone):\n",
    "                    print(\"failed\")\n",
    "                    \n",
    "            rowOffset = rowOffset + (blockSize-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def maskImages(train_images_dir,labels_chips_dir, LU_LABELS):\n",
    "    for filename in os.listdir(train_images_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            training_image_path = os.path.join(train_images_dir,filename)\n",
    "            #create a list of output ndarrays\n",
    "            mask_array = []\n",
    "            #iterate through the mask vectors\n",
    "            with rasterio.open(training_image_path) as src:\n",
    "                for LU_LABEL in LU_LABELS:\n",
    "                    masks = LU_LABELS[LU_LABEL]\n",
    "                    mask_image, mask_transform = rasterio.mask.mask(src,masks,nodata=0)\n",
    "                    mask_meta = src.meta.copy()\n",
    "                    mask_image[mask_image != 0] = LU_LABEL\n",
    "                    # only use the masked cells from blue band as its identical to others\n",
    "                    mask_array.append(mask_image[0]) \n",
    "            \n",
    "                #merge the masks into a single image\n",
    "                #by an element-wise maximum operator\n",
    "                #assumes that we dont have overlapping masks\n",
    "                final_mask = mask_array[0].copy()\n",
    "                for p in range(1,len(mask_array)):\n",
    "                    final_mask = np.maximum(final_mask,mask_array[p]).copy()\n",
    "\n",
    "                final_mask = final_mask.astype('uint8')\n",
    "                final_mask[final_mask < 1] = 0\n",
    "                \n",
    "                # skip this tile if it only has nodata otherwise\n",
    "                # we are overfeeding nodata\n",
    "                uniqueLabels = np.unique(final_mask)\n",
    "                if len(uniqueLabels) < 2 and uniqueLabels[0] ==0:\n",
    "                    continue\n",
    "                    \n",
    "                final_mask = np.expand_dims(final_mask, 0)\n",
    "            \n",
    "                #save the final mask image\n",
    "                mask_meta.update({'driver': 'GTiff',\n",
    "                             'dtype': 'uint8',\n",
    "                             'count': 1,\n",
    "                             'height': final_mask.shape[1],\n",
    "                             'width': final_mask.shape[2],\n",
    "                             'transform': mask_transform,\n",
    "                             'nodata':0})\n",
    "                label_file_name = os.path.join(labels_chips_dir,filename.replace(\".tif\",\"_labels.tif\"))\n",
    "                with rasterio.open(label_file_name, 'w', **mask_meta) as dest:\n",
    "                    dest.write(final_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskImage(input_image_name,allPolygons):\n",
    "    try:\n",
    "        temp_file_name = input_image_name.replace(\".tif\",\"_temp.tif\")\n",
    "        maskDone = False\n",
    "        with rasterio.open(input_image_name) as src:\n",
    "            mask_image, mask_transform = rasterio.mask.mask(src,allPolygons,nodata=0)\n",
    "            mask_meta = src.meta.copy()            \n",
    "            # skip this tile if it only has nodata otherwise\n",
    "            # we are overfeeding nodata\n",
    "            uniqueLabels = np.unique(mask_image[0,:,:])\n",
    "            if len(uniqueLabels) < 2 and uniqueLabels[0] ==0:                \n",
    "                maskDone= input_image_name\n",
    "            else:\n",
    "                with rasterio.open(temp_file_name, 'w', **mask_meta) as dest:\n",
    "                    dest.write(mask_image)\n",
    "                    maskDone = temp_file_name\n",
    "        \n",
    "        if (maskDone == input_image_name):\n",
    "            os.remove(input_image_name)\n",
    "        elif (maskDone == temp_file_name):\n",
    "            os.remove(input_image_name)\n",
    "            os.rename(temp_file_name,input_image_name)\n",
    "        return True    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return maskDone\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data polygons from landcover shapefile\n",
    "# open the landcover polygons and create an array of geometries for unique LU_LABELS\n",
    "def makeMasks(shapeFileName,labelFieldName):\n",
    "    LU_LABELS = {}\n",
    "    with fiona.open(shapeFileName, 'r') as landcovers:\n",
    "        for feature in landcovers:\n",
    "            LU_LABEL = feature['properties'][labelFieldName]\n",
    "            landcover = feature[\"geometry\"]\n",
    "            if LU_LABEL in LU_LABELS:\n",
    "                oldArray = LU_LABELS[LU_LABEL]\n",
    "                oldArray.append(landcover)\n",
    "            else:\n",
    "                LU_LABELS[LU_LABEL] = [landcover]\n",
    "    return LU_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate all metrics\n",
    "def accuracy_statistics(true_class, predicted_class):\n",
    "   \n",
    "    # classification report\n",
    "    #target_names = [\"Class {}\".format(i) for i in range(3)]\n",
    "    print('Classification Report')\n",
    "    print(classification_report(true_class, predicted_class))\n",
    "   \n",
    "    # jaccard\n",
    "    # print('Jaccard Score:')\n",
    "    # print(jaccard_similarity_score(true_class, predicted_class))\n",
    "   \n",
    "    # confusion matrix\n",
    "    print ('Confusion Matrix')\n",
    "    #print(confusion_matrix(true_class, predicted_class))\n",
    "    cnf_matrix = confusion_matrix(true_class, predicted_class)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['NoData', 'Solar Panel', 'Trees','Built Structure','Pond'],\n",
    "                          title='Confusion matrix, without normalization')\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['NoData', 'Solar Panel', 'Trees','Built Structure','Pond'], normalize=True,\n",
    "                          title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read land cover polygon  into geometry arrays that rasterio will use to create masks\n",
    "labels_shp = os.path.join(labels_dir, 'Labels4Classes.shp')\n",
    "LU_LABELS = makeMasks(labels_shp,'LU_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a global list of vectors for creating nodata area in RGB Images\n",
    "allPolygons = []\n",
    "for LU_LABEL in LU_LABELS:\n",
    "    allPolygons.extend(LU_LABELS[LU_LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess the training RGB , split into small tiles\n",
    "# create no data areas\n",
    "train_chips_dir = os.path.join(image_chips_dir, 'TRAIN')\n",
    "prepImages(ap_rgb_train_dir,train_chips_dir,allPolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells to run after file export\n",
    "# using rasterio mask function to mask pixels using LU_LABEL in the training images\n",
    "train_images_dir = os.path.join(image_chips_dir,'TRAIN')\n",
    "train_labels_chips_dir = os.path.join(train_images_dir,'LABELS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskImages(train_images_dir,train_labels_chips_dir,LU_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the test RGB and CIR images to resample CIR, extract NIR band, append NIR band to RGB, split into small tiles\n",
    "test_chips_dir = os.path.join(image_chips_dir, 'TEST')\n",
    "prepImages(ap_rgb_test_dir,test_chips_dir,allPolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells to run after file export\n",
    "test_images_dir = os.path.join(image_chips_dir,'TEST')\n",
    "test_labels_chips_dir = os.path.join(test_images_dir,'LABELS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using rasterio mask function to mask pixels using LU_LABEL in the test images\n",
    "maskImages(test_images_dir,test_labels_chips_dir,LU_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "The last approach will implement Unet - a popular convolutional neural network for image classifcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to the training data\n",
    "image_chips = train_images_dir\n",
    "label_chips = train_labels_chips_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to store data and respective labels\n",
    "# imagese are split into halves..first half used for training, and remaining half into validation\n",
    "class train_data():\n",
    "    \n",
    "    def __init__(self, image, label):\n",
    "        self.image = []\n",
    "        self.label = []\n",
    "        for file in os.listdir(image):\n",
    "            if file.endswith(\".tif\"):\n",
    "                label_file= os.path.join(label,file.replace(\".tif\",\"_labels.tif\"))\n",
    "                self.image.append(io.imread(image+\"/\"+file,0))\n",
    "                self.label.append(io.imread(label_file,0))\n",
    "    \n",
    "    # training half\n",
    "    def get_image(self):\n",
    "        return np.array(self.image[:int(len(self.image)/2)])\n",
    "\n",
    "    def get_label(self):\n",
    "        return np.array(self.label[:int(len(self.image)/2)])\n",
    "    \n",
    "    # validation half\n",
    "    def get_validation_image(self):\n",
    "        return np.array(self.image[int(len(self.image)/2):])\n",
    "    \n",
    "    def get_validation_label(self):\n",
    "        return np.array(self.label[int(len(self.image)/2):])\n",
    "        \n",
    "    def set_image(self, new_images):\n",
    "        self.image = new_image\n",
    "    \n",
    "    def set_label(self,new_label):\n",
    "        self.label = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training data creation\n",
    "train_set = train_data(image_chips, label_chips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the training set\n",
    "train_images = train_set.get_image()\n",
    "train_labels = train_set.get_label()\n",
    "# access the validation set\n",
    "validation_images = train_set.get_validation_image()\n",
    "validation_labels = train_set.get_validation_label()\n",
    "# one hot encode the labels\n",
    "train_labels_encoded = to_categorical(train_labels, num_classes=5)\n",
    "validation_labels_encoded = to_categorical(validation_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that Keras expects the bands to be passed last - i.e. the data is shaped (256, 256, 12)\n",
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Unet architecture\n",
    "def unet_cate(pretrained_weights = None,input_size = (256,256,3)):\n",
    "    # inputs = Input(shape=(256, 256, 4))\n",
    "    # two more bands have been added\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # use softmax in order to only output one class per pixel (unlike sigmoid which can have multiclass)\n",
    "    conv10 = Conv2D(5, (1, 1), activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "model = unet_cate()\n",
    "model.fit(train_images, train_labels_encoded, validation_data=(validation_images, validation_labels_encoded), epochs=50,\n",
    "          batch_size=8, shuffle=True)\n",
    "# save the model and weights\n",
    "model_path = os.path.join(model_dir, 'landcovers_Unet_50epoch_rgb.h5')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model(model_path)\n",
    "\n",
    "# increase the learning rate\n",
    "#lr = 0.00001\n",
    "#K.set_value(model.optimizer.lr, lr)\n",
    "\n",
    "#model.fit(train_images, train_labels_encoded, validation_data=(validation_images, validation_labels_encoded), epochs=10,\n",
    "#          batch_size=8, shuffle=True)\n",
    "#model_path = os.path.join(model_dir, '20181008_Unet_20epoch.h5')\n",
    "#model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = load_model(model_path)\n",
    "\n",
    "# try increasing the learning rate as little improvement was seen in previous epochs\n",
    "#lr = 0.000001\n",
    "#K.set_value(model.optimizer.lr, lr)\n",
    "\n",
    "#model.fit(train_images, train_labels_encoded, validation_data=(validation_images, validation_labels_encoded), epochs=10,\n",
    "#          batch_size=2, shuffle=True)\n",
    "#model_path = os.path.join(model_dir, '20181008_Unet_30epoch.h5')\n",
    "#model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the latest trained model\n",
    "unet_model = load_model(model_path)\n",
    "\n",
    "# non custom load model syntax\n",
    "#unet_model = load_model(modelPath,custom_objects={'dice_coef_loss': dice_coef_loss,'dice_coef':dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_image_chips = test_images_dir \n",
    "test_label_chips = test_labels_chips_dir \n",
    "\n",
    "class test_data():    \n",
    "    def __init__(self, image, label):\n",
    "        self.image = []\n",
    "        self.label = []\n",
    "        self.filename = [] # store the filename because we can use it later to recreate the predicted image for it\n",
    "        \n",
    "        for file in os.listdir(image):            \n",
    "            if file.endswith(\".tif\"):\n",
    "                label_file= os.path.join(label,file.replace(\".tif\",\"_labels.tif\"))\n",
    "                self.image.append(io.imread(image+\"/\"+file,0))\n",
    "                self.label.append(io.imread(label_file,0))\n",
    "                self.filename.append(file)\n",
    "               \n",
    "    def get_image(self):\n",
    "        return np.array(self.image[:int(len(self.image))])\n",
    "\n",
    "    def get_label(self):\n",
    "        return np.array(self.label[:int(len(self.image))])\n",
    "        \n",
    "    def set_image(self, new_images):\n",
    "        self.image = new_image\n",
    "    \n",
    "    def set_label(self,new_label):\n",
    "        self.label = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test set\n",
    "test_set = test_data(test_image_chips, test_label_chips)\n",
    "# access the test images and labels\n",
    "test_images = test_set.get_image()\n",
    "test_label = test_set.get_label()\n",
    "# one-hot-encode the labels\n",
    "test_label_encoded = to_categorical(test_label, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set using the trained model\n",
    "test_predict = unet_model.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode the predictions\n",
    "test_predict_decoded = np.argmax(test_predict, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate accuracy statistics\n",
    "accuracy_statistics(test_label.ravel(), test_predict_decoded.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing\n",
    "In order to generate coastline from the predicted regions, some post-processing is necessary to re-establish the order of the image tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the test_images, find the related predicted arrays, find the geotransformation of the test_image it came from\n",
    "# and the save the predicted array as an image using the geotransform\n",
    "for tileNum in range(len(test_predict_decoded)):\n",
    "    imgFileName = test_set.filename[tileNum]\n",
    "    imageFullName = os.path.join(test_image_chips,imgFileName)\n",
    "    with rasterio.open(imageFullName) as src:\n",
    "        out_transform = src.transform\n",
    "        out_meta = {'driver': 'GTiff',\n",
    "                    'dtype': 'uint8',\n",
    "                    'count': 1,\n",
    "                    'height': 256,\n",
    "                    'width': 256,\n",
    "                    'crs': src.crs,\n",
    "                    'transform': out_transform,\n",
    "                    'nodata':0}\n",
    "        predictionFileName = os.path.join(predictions_dir,imgFileName.replace(\".tif\",\"_prediction.tif\"))\n",
    "        with rasterio.open(predictionFileName, 'w', **out_meta) as dest:\n",
    "                    im_prediction = test_predict_decoded[tileNum,:,:]\n",
    "                    im_prediction = np.expand_dims(im_prediction, 0)\n",
    "                    im_prediction = im_prediction.astype('uint8')\n",
    "                    dest.write(im_prediction) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
