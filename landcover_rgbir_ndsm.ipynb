{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation for non-agricultural land covers based on U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initliasations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T06:01:23.890179Z",
     "start_time": "2018-10-14T06:01:23.544180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy for numerical processing and arrays\n",
    "import numpy as np\n",
    "\n",
    "# Useful python libaries for manipulating data\n",
    "import pickle\n",
    "import itertools\n",
    "import glob\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geospatial libraries to handle georeferenced raster and vector data\n",
    "import fiona\n",
    "from fiona import collection\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, mapping, shape\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio import windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib for data plotting\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit learn and scikit image libraries for machine learning and computer vision tools.\n",
    "from skimage import io, exposure, measure\n",
    "from sklearn.metrics import jaccard_similarity_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# Keras deep learning library\n",
    "import keras\n",
    "from keras.models import load_model, Model\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializse a random number generator to ensure results are reproducible\n",
    "np.random.seed(7)\n",
    "# turn warnig off\n",
    "np.warnings.filterwarnings('ignore')\n",
    "# print floating points as using fixed point notation i.e. not scientific\n",
    "np.set_printoptions(suppress=True)\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delcare whether its only RGB-IR Indices or RGB-IR-SLOPE\n",
    "appendDSM=True\n",
    "folderRunSuffix = 'RGBIR_NDSM'\n",
    "numChannels = 7\n",
    "appendIR=False\n",
    "if appendDSM and appendIR:\n",
    "    numChannels = 7\n",
    "    folderRunSuffix = 'RGBIR_NDSM'\n",
    "elif not appendDSM and appendIR:\n",
    "    numChannels = 6\n",
    "    folderRunSuffix = 'RGBIR'\n",
    "elif not appendIR and appendDSM:\n",
    "    numChannels = 4\n",
    "    folderRunSuffix = 'RGB_nDSM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells to run after file export\n",
    "# set some useful paths\n",
    "# RAW INPUTS\n",
    "root = '/Volumes/NewVolume/DSA/Classify_LandCover/'\n",
    "ap_rgb_train_dir = os.path.join(root, 'DATA/AP_RGB_TRAIN')  # full res input RGB AP for training\n",
    "ap_cir_train_dir = os.path.join(root, 'DATA/AP_CIR_TRAIN')  # full res input CIR for training\n",
    "ap_rgb_test_dir = os.path.join(root, 'DATA/AP_RGB_TEST')  # full res input RGB AP for testing\n",
    "ap_cir_test_dir = os.path.join(root, 'DATA/AP_CIR_TEST')  # full res input CIR for testing\n",
    "\n",
    "labels_dir = os.path.join(root, 'DATA/LABELS')  # land cover polygons after generalisation\n",
    "\n",
    "dsm_dir = os.path.join(root, 'DATA/N_DSM')  # DSM \n",
    "\n",
    "# DERIVED INPUTS\n",
    "image_chips_dir = os.path.join(root, 'DATA/IMAGE_CHIPS',folderRunSuffix)  # pre-procssed image tiles and mask root folder\n",
    "if (not os.path.exists(image_chips_dir)):\n",
    "    os.mkdir(image_chips_dir)\n",
    "model_dir = os.path.join(root, 'MODELS',folderRunSuffix)  # contains the machine learning models\n",
    "if (not os.path.exists(model_dir)):\n",
    "    os.mkdir(model_dir)\n",
    "predictions_dir = os.path.join(root, 'PREDICTIONS','UNET',folderRunSuffix)\n",
    "if (not os.path.exists(predictions_dir)):\n",
    "    os.mkdir(predictions_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function by cate to create 3D tiles \n",
    "def get_tile_images(arr, newshape):\n",
    "    oldshape = np.array(arr.shape)\n",
    "    repeats = (oldshape / newshape).astype(int)\n",
    "    tmpshape = np.column_stack([repeats, newshape]).ravel()\n",
    "    order = np.arange(len(tmpshape))\n",
    "    order = np.concatenate([order[::2], order[1::2]])\n",
    "    #pdb.set_trace()\n",
    "    # newshape must divide oldshape evenly or else ValueError will be raised\n",
    "    return arr.reshape(tmpshape).transpose(order).reshape(-1, *newshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first 3 bands from 4-band RGBA\n",
    "# extract the first band (NIR) from 3-band CIR\n",
    "# resample the NIR band to 25cm\n",
    "# append the NIR band  onto the RGB image\n",
    "# append the slope image\n",
    "\n",
    "def appendMoreBands(RGB_ImageName, CIR_ImageName,nDSM_ImageName, tileYSize, tileXSize):\n",
    "\n",
    "    with rasterio.open(RGB_ImageName) as rgb_src:\n",
    "        newHeight = int(rgb_src.height / tileYSize) * tileYSize\n",
    "        newWidth = int(rgb_src.height / tileXSize) * tileXSize\n",
    "        # only read image upto size  to which tiling can be done into 256x256 blocks\n",
    "        # numpy.ndarray - read the first three bands as the last band is alpha\n",
    "        rgb_image = rgb_src.read([1, 2, 3], window=((0, newWidth), (0, newHeight)))\n",
    "        # show(rgb_image)\n",
    "        out_metadata = rgb_src.meta.copy()\n",
    "        out_transform = rgb_src.transform\n",
    "            \n",
    "    if (not CIR_ImageName is None):\n",
    "        with rasterio.open(CIR_ImageName) as nir_src:\n",
    "            nir_image = nir_src.read([1], window=(\n",
    "            (0, newWidth / 2), (0, newHeight / 2)))  # only read in the first band as its the NIR band\n",
    "            # show(nir_image)\n",
    "            # upsample the CIR band to match the RGB band\n",
    "            new_nir_image = np.empty(shape=(nir_image.shape[0],  # same number of bands\n",
    "                                        round(nir_image.shape[1] * 2),  # 200% resolution\n",
    "                                        round(nir_image.shape[2] * 2)))\n",
    "            # upsample the NIR image to 25cm i.e. adjust the new affine transform to the 50% smaller cell size\n",
    "            aff = nir_src.transform\n",
    "            newaff = Affine(aff.a / 2, aff.b, aff.c, aff.d, aff.e / 2, aff.f)\n",
    "        \n",
    "            reproject(\n",
    "                nir_image, new_nir_image,\n",
    "                src_transform=aff,\n",
    "                dst_transform=newaff,\n",
    "                src_crs=nir_src.crs,\n",
    "                dst_crs=nir_src.crs,\n",
    "                resampling=Resampling.nearest)\n",
    "            # print(new_nir_image.shape)\n",
    "            # show(new_nir_image)   \n",
    "\n",
    "            rgbir = np.append(rgb_image,new_nir_image,axis=0)    \n",
    "        rgbir_with_indices = add_veg_indices(rgbir)\n",
    "    \n",
    "    \n",
    "    #add slope if asked for\n",
    "    if (not nDSM_ImageName is None):\n",
    "        with rasterio.open(nDSM_ImageName) as nDSM_src:\n",
    "            newHeight = int(nDSM_src.height / tileYSize) * tileYSize\n",
    "            newWidth = int(nDSM_src.height / tileXSize) * tileXSize\n",
    "            # only read image upto size  to which tiling can be done into 256x256 blocks\n",
    "            # numpy.ndarray - read the first three bands as the last band is alpha\n",
    "            nDSM_image = nDSM_src.read([1],window=((0, newWidth), (0, newHeight)))\n",
    "            if appendIR:\n",
    "                rgbir_with_indices = np.append(rgbir_with_indices,nDSM_image,axis=0)\n",
    "            else:\n",
    "                rgbir_with_indices = np.append(rgb_image,nDSM_image,axis=0)\n",
    "            \n",
    "    rgbir_with_indices_normalised = keras.utils.normalize(rgbir_with_indices,axis=2)\n",
    "    return rgbir_with_indices_normalised, out_metadata, out_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepImages(ap_rgb_train_dir,ap_cir_train_dir,image_chips_dir,allPolygons,appendDSM):\n",
    "    # read the rgb and cir images that we have and store them in a dictionary\n",
    "    rgb_list = {}\n",
    "    for filename in os.listdir(ap_rgb_train_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            # get os1k tile name\n",
    "            os1k_tile = filename[:6]\n",
    "            if os1k_tile in rgb_list:\n",
    "                print(os1k_tile + 'already exists so summin wrong?!')\n",
    "                continue\n",
    "            else:\n",
    "                rgb_list[os1k_tile]= os.path.join(ap_rgb_train_dir, filename)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    cir_list = {}\n",
    "    for filename in os.listdir(ap_cir_train_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            # get os1k tile name\n",
    "            os1k_tile = filename[:6]\n",
    "            if os1k_tile in cir_list:\n",
    "                print(os1k_tile + 'already exists so summin wrong?!')\n",
    "                continue\n",
    "            else:\n",
    "                cir_list[os1k_tile]= os.path.join(ap_cir_train_dir, filename)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # make sure that the rgb and nir image list size are identical\n",
    "    if len(rgb_list) != len(cir_list):\n",
    "        raise ValueError('RGB and CIR image lists are not identical')\n",
    "    \n",
    "    if len(rgb_list) < 1 or len(cir_list) < 1:\n",
    "        raise ValueError('RGB and CIR image lists are empty')\n",
    "    \n",
    "    # iterate through the RGB and CIR images \n",
    "    # use only the first band (i.e. NIR) from CIR\n",
    "    # resample NIR to 25 cms\n",
    "    # append NIR to RGB\n",
    "    # create image chips\n",
    "    for os1k_tile in rgb_list:\n",
    "        rgb_image = rgb_list[os1k_tile]\n",
    "        if os1k_tile not in cir_list:\n",
    "            raise ValueError(os1k_tile + ' not found in cir list - no bueno')\n",
    "        else:\n",
    "            cir_image = cir_list[os1k_tile]\n",
    "        \n",
    "        ndsm_image = os.path.join(dsm_dir,os1k_tile+'_ndsm.tif')\n",
    "        if (appendDSM):                    \n",
    "            if not os.path.exists(ndsm_image):\n",
    "                raise ValueError('No slope image: '+ndsm_image)\n",
    "\n",
    "        if appendDSM and appendIR:\n",
    "             rgbir_image, inputMetadata, inputTransform = appendMoreBands(rgb_image,cir_image,ndsm_image,256,256)\n",
    "        elif appendIR and not appendDSM:\n",
    "            rgbir_image, inputMetadata, inputTransform = appendMoreBands(rgb_image,cir_image,None,256,256)\n",
    "        elif not appendIR and appendDSM:\n",
    "            print (\"calling ndsm\")\n",
    "            rgbir_image, inputMetadata, inputTransform = appendMoreBands(rgb_image,None,ndsm_image,256,256)\n",
    "        else:\n",
    "            raise ValueError(\"dunno what happened\")\n",
    "        \n",
    "        # Affine(0.25,0.0,462000.0,0.0,-0.25,372000.0)\n",
    "        ULX = inputTransform.c\n",
    "        ULY = inputTransform.f\n",
    "        cellSizeX = inputTransform.a\n",
    "        cellSizeY = inputTransform.e\n",
    "        \n",
    "        # 2 more bands have been added\n",
    "        rgbir_image_tiled = get_tile_images(rgbir_image,(numChannels,256,256))\n",
    "     \n",
    "        # write image chips\n",
    "        numtiles,numbands,rows,cols = rgbir_image_tiled.shape\n",
    "        rowOffset = 0\n",
    "        blockSize = int(math.sqrt(numtiles))\n",
    "        for tileIndexAlongY in range(0,blockSize):\n",
    "            tileULY = ULY + (tileIndexAlongY * cellSizeY * 256)\n",
    "            for tileIndexAlongX in range(0,blockSize):\n",
    "                tileULX = ULX + (tileIndexAlongX * cellSizeX * 256)\n",
    "                # print(str(tileULX)+\",\"+str(tileULY))\n",
    "                globalTileIndex = tileIndexAlongY + tileIndexAlongX + rowOffset\n",
    "                aTileImage = rgbir_image_tiled[globalTileIndex,:,:,:]\n",
    "                # aTileImage = np.expand_dims(aTileImage,0)\n",
    "                tileMetadata = inputMetadata.copy()\n",
    "                tileTransform = Affine(cellSizeX,\n",
    "                                   inputTransform.b,\n",
    "                                   tileULX,\n",
    "                                   inputTransform.d,\n",
    "                                   cellSizeY,\n",
    "                                   tileULY)\n",
    "                \n",
    "                # two more bands have been added                \n",
    "                tileMetadata.update({'driver': 'GTiff',\n",
    "                                 'dtype': 'float64',\n",
    "                                 'count': numChannels,\n",
    "                                 'height': 256,\n",
    "                                 'width': 256,\n",
    "                                 'transform': tileTransform,\n",
    "                                 'nodata':0})\n",
    "                \n",
    "                tileFileName = os.path.basename(rgb_image).replace(\".tif\",\"_\"+str(globalTileIndex).zfill(4)+\".tif\")\n",
    "                tileFullName = os.path.join(image_chips_dir, tileFileName)\n",
    "                with rasterio.open(tileFullName, 'w', **tileMetadata) as dest:\n",
    "                    dest.write(aTileImage)\n",
    "                \n",
    "                #now mask nodata areas in the image\n",
    "                maskDone = maskImage(tileFullName,allPolygons)\n",
    "                if (not maskDone):\n",
    "                    print(\"failed\")\n",
    "                    \n",
    "            rowOffset = rowOffset + (blockSize-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_veg_indices(image):\n",
    "    red = image[0,:,:]\n",
    "    green = image[1,:,:]\n",
    "    blue = image[2,:,:]\n",
    "    nir = image[3,:,:]   \n",
    "    \n",
    "    red_diff = np.subtract(nir,red)\n",
    "    red_sum = np.add(nir,red)\n",
    "    ndvi = np.divide(red_diff,red_sum,out=np.zeros_like(red_diff), where=red_sum!=0)\n",
    "    \n",
    "    red_green_diff = np.subtract(green,nir)\n",
    "    red_green_sum = np.add(green,nir)\n",
    "\n",
    "    ndwi = np.divide(red_green_diff,red_green_sum,out=np.zeros_like(red_green_diff), where=red_green_sum!=0)\n",
    "    \n",
    "    new_image = np.stack((image[0,:,:],image[1,:,:],image[2,:,:],image[3,:,:],ndvi,ndwi),axis=0)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def maskImages(train_images_dir,labels_chips_dir, LU_LABELS):\n",
    "    for filename in os.listdir(train_images_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            training_image_path = os.path.join(train_images_dir,filename)\n",
    "            #create a list of output ndarrays\n",
    "            mask_array = []\n",
    "            #iterate through the mask vectors\n",
    "            with rasterio.open(training_image_path) as src:\n",
    "                for LU_LABEL in LU_LABELS:\n",
    "                    masks = LU_LABELS[LU_LABEL]\n",
    "                    mask_image, mask_transform = rasterio.mask.mask(src,masks,nodata=0)\n",
    "                    mask_meta = src.meta.copy()\n",
    "                    mask_image[mask_image != 0] = LU_LABEL\n",
    "                    # only use the masked cells from blue band as its identical to others\n",
    "                    mask_array.append(mask_image[0]) \n",
    "            \n",
    "                #merge the masks into a single image\n",
    "                #by an element-wise maximum operator\n",
    "                #assumes that we dont have overlapping masks\n",
    "                final_mask = mask_array[0].copy()\n",
    "                for p in range(1,len(mask_array)):\n",
    "                    final_mask = np.maximum(final_mask,mask_array[p]).copy()\n",
    "\n",
    "                final_mask = final_mask.astype('uint8')\n",
    "                final_mask[final_mask < 1] = 0\n",
    "                \n",
    "                # skip this tile if it only has nodata otherwise\n",
    "                # we are overfeeding nodata\n",
    "                uniqueLabels = np.unique(final_mask)\n",
    "                if len(uniqueLabels) < 2 and uniqueLabels[0] ==0:\n",
    "                    continue\n",
    "                    \n",
    "                final_mask = np.expand_dims(final_mask, 0)\n",
    "            \n",
    "                #save the final mask image\n",
    "                mask_meta.update({'driver': 'GTiff',\n",
    "                             'dtype': 'uint8',\n",
    "                             'count': 1,\n",
    "                             'height': final_mask.shape[1],\n",
    "                             'width': final_mask.shape[2],\n",
    "                             'transform': mask_transform,\n",
    "                             'nodata':0})\n",
    "                label_file_name = os.path.join(labels_chips_dir,filename.replace(\".tif\",\"_labels.tif\"))\n",
    "                with rasterio.open(label_file_name, 'w', **mask_meta) as dest:\n",
    "                    dest.write(final_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskImage(input_image_name,allPolygons):\n",
    "    try:\n",
    "        temp_file_name = input_image_name.replace(\".tif\",\"_temp.tif\")\n",
    "        maskDone = False\n",
    "        with rasterio.open(input_image_name) as src:\n",
    "            mask_image, mask_transform = rasterio.mask.mask(src,allPolygons,nodata=0)\n",
    "            mask_meta = src.meta.copy()            \n",
    "            # skip this tile if it only has nodata otherwise\n",
    "            # we are overfeeding nodata\n",
    "            uniqueLabels = np.unique(mask_image[0,:,:])\n",
    "            if len(uniqueLabels) < 2 and uniqueLabels[0] ==0:                \n",
    "                maskDone= input_image_name\n",
    "            else:\n",
    "                with rasterio.open(temp_file_name, 'w', **mask_meta) as dest:\n",
    "                    dest.write(mask_image)\n",
    "                    maskDone = temp_file_name\n",
    "        \n",
    "        if (maskDone == input_image_name):\n",
    "            os.remove(input_image_name)\n",
    "        elif (maskDone == temp_file_name):\n",
    "            os.remove(input_image_name)\n",
    "            os.rename(temp_file_name,input_image_name)\n",
    "        return True    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return maskDone\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data polygons from landcover shapefile\n",
    "# open the landcover polygons and create an array of geometries for unique LU_LABELS\n",
    "def makeMasks(shapeFileName,labelFieldName):\n",
    "    LU_LABELS = {}\n",
    "    with fiona.open(shapeFileName, 'r') as landcovers:\n",
    "        for feature in landcovers:\n",
    "            LU_LABEL = feature['properties'][labelFieldName]\n",
    "            landcover = feature[\"geometry\"]\n",
    "            if LU_LABEL in LU_LABELS:\n",
    "                oldArray = LU_LABELS[LU_LABEL]\n",
    "                oldArray.append(landcover)\n",
    "            else:\n",
    "                LU_LABELS[LU_LABEL] = [landcover]\n",
    "    return LU_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate all metrics\n",
    "def accuracy_statistics(true_class, predicted_class):\n",
    "   \n",
    "    # classification report\n",
    "    #target_names = [\"Class {}\".format(i) for i in range(3)]\n",
    "    print('Classification Report')\n",
    "    print(classification_report(true_class, predicted_class))\n",
    "   \n",
    "    # jaccard\n",
    "    print('Jaccard Score:')\n",
    "    print(jaccard_similarity_score(true_class, predicted_class))\n",
    "   \n",
    "    # confusion matrix\n",
    "    # plt.figure()\n",
    "    print ('Confusion Matrix')\n",
    "    #print(confusion_matrix(true_class, predicted_class))\n",
    "    cnf_matrix = confusion_matrix(true_class, predicted_class)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['NoData', 'Solar Panel', 'Trees','Built Structure','Pond'],\n",
    "                          title='Confusion matrix, without normalization')\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['NoData', 'Solar Panel', 'Trees','Built Structure','Pond'], normalize=True,\n",
    "                          title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read land cover polygon  into geometry arrays that rasterio will use to create masks\n",
    "labels_shp = os.path.join(labels_dir, 'Labels4Classes.shp')\n",
    "LU_LABELS = makeMasks(labels_shp,'LU_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a global list of vectors for creating nodata area in RGB Images\n",
    "allPolygons = []\n",
    "for LU_LABEL in LU_LABELS:\n",
    "    allPolygons.extend(LU_LABELS[LU_LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preprocess the training RGB and CIR images to resample CIR, extract NIR band, \n",
    "# append NIR band to RGB, split into small tiles\n",
    "# create no data areas\n",
    "train_chips_dir = os.path.join(image_chips_dir, 'TRAIN')\n",
    "if (not os.path.exists(train_chips_dir)):\n",
    "    os.mkdir(train_chips_dir)\n",
    "prepImages(ap_rgb_train_dir,ap_cir_train_dir,train_chips_dir,allPolygons,appendDSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells to run after file export\n",
    "# using rasterio mask function to mask pixels using LU_LABEL in the training images\n",
    "train_images_dir = os.path.join(image_chips_dir,'TRAIN')\n",
    "\n",
    "train_labels_chips_dir = os.path.join(train_images_dir,'LABELS')\n",
    "if (not os.path.exists(train_labels_chips_dir)):\n",
    "    os.mkdir(train_labels_chips_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskImages(train_images_dir,train_labels_chips_dir,LU_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the test RGB and CIR images to resample CIR, extract NIR band, append NIR band to RGB, split into small tiles\n",
    "test_chips_dir = os.path.join(image_chips_dir, 'TEST')\n",
    "if (not os.path.exists(test_chips_dir)):\n",
    "    os.mkdir(test_chips_dir)\n",
    "prepImages(ap_rgb_test_dir,ap_cir_test_dir,test_chips_dir,allPolygons,appendDSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells to run after file export\n",
    "test_images_dir = os.path.join(image_chips_dir,'TEST')\n",
    "\n",
    "test_labels_chips_dir = os.path.join(test_images_dir,'LABELS')\n",
    "if (not os.path.exists(test_labels_chips_dir)):\n",
    "    os.mkdir(test_labels_chips_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using rasterio mask function to mask pixels using LU_LABEL in the test images\n",
    "maskImages(test_images_dir,test_labels_chips_dir,LU_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "The last approach will implement Unet - a popular convolutional neural network for image classifcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to the training data\n",
    "image_chips = train_images_dir\n",
    "label_chips = train_labels_chips_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to store data and respective labels\n",
    "# imagese are split into halves..first half used for training, and remaining half into validation\n",
    "class train_data():\n",
    "    \n",
    "    def __init__(self, image, label):\n",
    "        self.image = []\n",
    "        self.label = []\n",
    "        for file in os.listdir(image):\n",
    "            if file.endswith(\".tif\"):\n",
    "                label_file= os.path.join(label,file.replace(\".tif\",\"_labels.tif\"))\n",
    "                self.image.append(io.imread(image+\"/\"+file,0))\n",
    "                self.label.append(io.imread(label_file,0))\n",
    "    \n",
    "    # training half\n",
    "    def get_image(self):\n",
    "        return np.array(self.image[:int(len(self.image)/2)])\n",
    "\n",
    "    def get_label(self):\n",
    "        return np.array(self.label[:int(len(self.image)/2)])\n",
    "    \n",
    "    # validation half\n",
    "    def get_validation_image(self):\n",
    "        return np.array(self.image[int(len(self.image)/2):])\n",
    "    \n",
    "    def get_validation_label(self):\n",
    "        return np.array(self.label[int(len(self.image)/2):])\n",
    "        \n",
    "    def set_image(self, new_images):\n",
    "        self.image = new_image\n",
    "    \n",
    "    def set_label(self,new_label):\n",
    "        self.label = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training data creation\n",
    "train_set = train_data(image_chips, label_chips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the training set\n",
    "train_images = train_set.get_image()\n",
    "train_labels = train_set.get_label()\n",
    "# access the validation set\n",
    "validation_images = train_set.get_validation_image()\n",
    "validation_labels = train_set.get_validation_label()\n",
    "# one hot encode the labels\n",
    "train_labels_encoded = to_categorical(train_labels, num_classes=5)\n",
    "validation_labels_encoded = to_categorical(validation_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that Keras expects the bands to be passed last - i.e. the data is shaped (256, 256, 12)\n",
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Unet architecture\n",
    "def unet_cate(pretrained_weights = None,input_size = (256,256,numChannels)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # use softmax in order to only output one class per pixel (unlike sigmoid which can have multiclass)\n",
    "    conv10 = Conv2D(5, (1, 1), activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    # see if a different loss and metrics can improve e.g. sorenson-dice\n",
    "    # model.compile(optimizer=Adam(lr=1e-9), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # model.compile(optimizer=Adam(lr=1e-9), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model = unet_cate()\n",
    "model.fit(train_images, train_labels_encoded, validation_data=(validation_images, validation_labels_encoded), epochs=50,\n",
    "          batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the model and weights\n",
    "model_path = os.path.join(model_dir, 'landcovers_Unet_50epoch_'+folderRunSuffix+'.h5')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model(model_path)\n",
    "\n",
    "# increase the learning rate\n",
    "#lr = 0.00001\n",
    "#K.set_value(model.optimizer.lr, lr)\n",
    "\n",
    "#model.fit(train_images, train_labels_encoded, validation_data=(validation_images, validation_labels_encoded), epochs=10,\n",
    "#          batch_size=8, shuffle=True)\n",
    "#model_path = os.path.join(model_dir, '20181008_Unet_20epoch.h5')\n",
    "#model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = load_model(model_path)\n",
    "\n",
    "# try increasing the learning rate as little improvement was seen in previous epochs\n",
    "#lr = 0.000001\n",
    "#K.set_value(model.optimizer.lr, lr)\n",
    "\n",
    "#model.fit(train_images, train_labels_encoded, validation_data=(validation_images, validation_labels_encoded), epochs=10,\n",
    "#          batch_size=2, shuffle=True)\n",
    "#model_path = os.path.join(model_dir, '20181008_Unet_30epoch.h5')\n",
    "#model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the latest trained model\n",
    "unet_model = load_model(model_path)\n",
    "\n",
    "# non custom load model syntax\n",
    "#unet_model = load_model(modelPath,custom_objects={'dice_coef_loss': dice_coef_loss,'dice_coef':dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_image_chips = test_images_dir \n",
    "test_label_chips = test_labels_chips_dir \n",
    "\n",
    "class test_data():\n",
    "    \n",
    "    def __init__(self, image, label):\n",
    "        self.image = []\n",
    "        self.label = []\n",
    "        self.filename = [] # store the filename because we can use it later to recreate the predicted image for it\n",
    "        \n",
    "        for file in os.listdir(image):\n",
    "            \n",
    "            if file.endswith(\".tif\"):\n",
    "                label_file= os.path.join(label,file.replace(\".tif\",\"_labels.tif\"))\n",
    "                self.image.append(io.imread(image+\"/\"+file,0))\n",
    "                self.label.append(io.imread(label_file,0))\n",
    "                self.filename.append(file)\n",
    "               \n",
    "    def get_image(self):\n",
    "        return np.array(self.image[:int(len(self.image))])\n",
    "\n",
    "    def get_label(self):\n",
    "        return np.array(self.label[:int(len(self.image))])\n",
    "        \n",
    "    def set_image(self, new_images):\n",
    "        self.image = new_image\n",
    "    \n",
    "    def set_label(self,new_label):\n",
    "        self.label = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test set\n",
    "test_set = test_data(test_image_chips, test_label_chips)\n",
    "# access the test images and labels\n",
    "test_images = test_set.get_image()\n",
    "test_label = test_set.get_label()\n",
    "# one-hot-encode the labels\n",
    "test_label_encoded = to_categorical(test_label, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set using the trained model\n",
    "test_predict = unet_model.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode the predictions\n",
    "test_predict_decoded = np.argmax(test_predict, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate accuracy statistics\n",
    "accuracy_statistics(test_label.ravel(), test_predict_decoded.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing\n",
    "In order to generate coastline from the predicted regions, some post-processing is necessary to re-establish the order of the image tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the test_images, find the related predicted arrays, find the geotransformation of the test_image it came from\n",
    "# and the save the predicted array as an image using the geotransform\n",
    "for tileNum in range(len(test_predict_decoded)):\n",
    "    imgFileName = test_set.filename[tileNum]\n",
    "    imageFullName = os.path.join(test_image_chips,imgFileName)\n",
    "    with rasterio.open(imageFullName) as src:\n",
    "        out_transform = src.transform\n",
    "        out_meta = {'driver': 'GTiff',\n",
    "                    'dtype': 'uint8',\n",
    "                    'count': 1,\n",
    "                    'height': 256,\n",
    "                    'width': 256,\n",
    "                    'crs': src.crs,\n",
    "                    'transform': out_transform,\n",
    "                    'nodata':0}\n",
    "        predictionFileName = os.path.join(predictions_dir, imgFileName.replace(\".tif\",\"_prediction.tif\"))\n",
    "        with rasterio.open(predictionFileName, 'w', **out_meta) as dest:\n",
    "                    im_prediction = test_predict_decoded[tileNum,:,:]\n",
    "                    im_prediction = np.expand_dims(im_prediction, 0)\n",
    "                    im_prediction = im_prediction.astype('uint8')\n",
    "                    dest.write(im_prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
