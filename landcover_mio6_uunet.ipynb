{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation for non-agricultural land covers based on U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initliasations\n",
    "\n",
    "# Numpy for numerical processing and arrays\n",
    "import numpy as np\n",
    "\n",
    "# Useful python libaries for manipulating data\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import pickle\n",
    "import itertools\n",
    "import glob\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "# Pandas to bring dataframe structure\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geospatial libraries to handle georeferenced raster and vector data\n",
    "import fiona\n",
    "from fiona import collection\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, mapping, shape\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio import windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib for data plotting\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit learn and scikit image libraries for machine learning and computer vision tools.\n",
    "from skimage import io, exposure, measure\n",
    "from sklearn.metrics import jaccard_similarity_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Keras deep learning library\n",
    "import keras\n",
    "from keras.models import load_model, Model\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, concatenate, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "#config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "#config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "#K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializse a random number generator to ensure results are reproducible\n",
    "np.random.seed(7)\n",
    "# turn warnig off\n",
    "np.warnings.filterwarnings('ignore')\n",
    "# print floating points as using fixed point notation i.e. not scientific\n",
    "np.set_printoptions(suppress=True)\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells to run after file export\n",
    "# set some useful paths\n",
    "# RAW INPUTS\n",
    "root = 'E:/projects/DSA/Classify_LandCover/'\n",
    "ap_rgb_train_dir = os.path.join(root, 'DATA/AP_RGB_TRAIN')  # full res input RGB AP for training\n",
    "ap_cir_train_dir = os.path.join(root, 'DATA/AP_CIR_TRAIN')  # full res input CIR for training\n",
    "ap_rgb_test_dir = os.path.join(root, 'DATA/AP_RGB_TEST')  # full res input RGB AP for testing\n",
    "ap_cir_test_dir = os.path.join(root, 'DATA/AP_CIR_TEST')  # full res input CIR for testing\n",
    "\n",
    "labels_dir = os.path.join(root, 'DATA/LABELS')  # land cover polygons after generalisation\n",
    "\n",
    "# DERIVED INPUTS\n",
    "image_chips_dir = os.path.join(root, 'DATA/IMAGE_CHIPS')  # pre-procssed image tiles and mask root folder\n",
    "model_dir = os.path.join(root, 'MODELS')  # contains the machine learning models\n",
    "predictions_dir = os.path.join(root, 'PREDICTIONS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function by cate to create 3D tiles \n",
    "def get_tile_images(arr, newshape):\n",
    "    oldshape = np.array(arr.shape)\n",
    "    repeats = (oldshape / newshape).astype(int)\n",
    "    tmpshape = np.column_stack([repeats, newshape]).ravel()\n",
    "    order = np.arange(len(tmpshape))\n",
    "    order = np.concatenate([order[::2], order[1::2]])\n",
    "    #pdb.set_trace()\n",
    "    # newshape must divide oldshape evenly or else ValueError will be raised\n",
    "    return arr.reshape(tmpshape).transpose(order).reshape(-1, *newshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first 3 bands from 4-band RGBA\n",
    "# extract the first band (NIR) from 3-band CIR\n",
    "# resample the NIR band to 25cm\n",
    "# append the NIR band  onto the RGB image\n",
    "\n",
    "def appendIRBand(RGB_ImageName, CIR_ImageName, tileYSize, tileXSize):\n",
    "\n",
    "    with rasterio.open(RGB_ImageName) as rgb_src:\n",
    "        newHeight = int(rgb_src.height / tileYSize) * tileYSize\n",
    "        newWidth = int(rgb_src.height / tileXSize) * tileXSize\n",
    "        # only read image upto size  to which tiling can be done into 256x256 blocks\n",
    "        # numpy.ndarray - read the first three bands as the last band is alpha\n",
    "        rgb_image = rgb_src.read([1, 2, 3], window=((0, newWidth), (0, newHeight)))\n",
    "        # show(rgb_image)\n",
    "        out_metadata = rgb_src.meta.copy()\n",
    "        out_transform = rgb_src.transform\n",
    "    \n",
    "\n",
    "    with rasterio.open(CIR_ImageName) as nir_src:\n",
    "        nir_image = nir_src.read([1], window=(\n",
    "        (0, newWidth / 2), (0, newHeight / 2)))  # only read in the first band as its the NIR band\n",
    "        # show(nir_image)\n",
    "        # upsample the CIR band to match the RGB band\n",
    "        new_nir_image = np.empty(shape=(nir_image.shape[0],  # same number of bands\n",
    "                                        round(nir_image.shape[1] * 2),  # 200% resolution\n",
    "                                        round(nir_image.shape[2] * 2)))\n",
    "        # upsample the NIR image to 25cm i.e. adjust the new affine transform to the 50% smaller cell size\n",
    "        aff = nir_src.transform\n",
    "        newaff = Affine(aff.a / 2, aff.b, aff.c, aff.d, aff.e / 2, aff.f)\n",
    "        \n",
    "        reproject(\n",
    "            nir_image, new_nir_image,\n",
    "            src_transform=aff,\n",
    "            dst_transform=newaff,\n",
    "            src_crs=nir_src.crs,\n",
    "            dst_crs=nir_src.crs,\n",
    "            resampling=Resampling.nearest)\n",
    "        # print(new_nir_image.shape)\n",
    "        # show(new_nir_image)\n",
    "    \n",
    "    rgbir = np.append(rgb_image,new_nir_image, axis=0)    \n",
    "    #return rgbir, out_metadata, out_transform\n",
    "    \n",
    "    # add more indices\n",
    "    rgbir_with_indices = add_indices(rgbir)  \n",
    "    rgbir_with_indices_normalised = keras.utils.normalize(rgbir_with_indices,axis=2)\n",
    "    return rgbir_with_indices_normalised, out_metadata, out_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepImages(ap_rgb_train_dir,ap_cir_train_dir,image_chips_dir,allPolygons):\n",
    "    # read the rgb and cir images that we have and store them in a dictionary\n",
    "    rgb_list = {}\n",
    "    for filename in os.listdir(ap_rgb_train_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            # get os1k tile name\n",
    "            os1k_tile = filename[:6]\n",
    "            if os1k_tile in rgb_list:\n",
    "                print(os1k_tile + 'already exists so summin wrong?!')\n",
    "                continue\n",
    "            else:\n",
    "                rgb_list[os1k_tile]= os.path.join(ap_rgb_train_dir, filename)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    cir_list = {}\n",
    "    for filename in os.listdir(ap_cir_train_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            # get os1k tile name\n",
    "            os1k_tile = filename[:6]\n",
    "            if os1k_tile in cir_list:\n",
    "                print(os1k_tile + 'already exists so summin wrong?!')\n",
    "                continue\n",
    "            else:\n",
    "                cir_list[os1k_tile]= os.path.join(ap_cir_train_dir, filename)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # make sure that the rgb and nir image list size are identical\n",
    "    if len(rgb_list) != len(cir_list):\n",
    "        raise ValueError('RGB and CIR image lists are not identical')\n",
    "    \n",
    "    if len(rgb_list) < 1 or len(cir_list) < 1:\n",
    "        raise ValueError('RGB and CIR image lists are empty')\n",
    "    \n",
    "    # iterate through the RGB and CIR images \n",
    "    # use only the first band (i.e. NIR) from CIR\n",
    "    # resample NIR to 25 cms\n",
    "    # append NIR to RGB\n",
    "    # create image chips\n",
    "    for os1k_tile in rgb_list:\n",
    "        rgb_image = rgb_list[os1k_tile]\n",
    "        if os1k_tile not in cir_list:\n",
    "            raise ValueError(os1k_tile + ' not found in cir list - no bueno')\n",
    "        else:\n",
    "            cir_image = cir_list[os1k_tile]\n",
    "        \n",
    "        \n",
    "        rgbir_image, inputMetadata, inputTransform = appendIRBand(rgb_image,cir_image,256,256)\n",
    "        \n",
    "        # Affine(0.25,0.0,462000.0,0.0,-0.25,372000.0)\n",
    "        ULX = inputTransform.c\n",
    "        ULY = inputTransform.f\n",
    "        cellSizeX = inputTransform.a\n",
    "        cellSizeY = inputTransform.e\n",
    "\n",
    "        # dimension of tiles must split rows/cols evenly otherwise valuerror\n",
    "        #rgbir_image_tiled = get_tile_images(rgbir_image,(4,256,256))\n",
    "        \n",
    "        # 2 more bands have been added\n",
    "        rgbir_image_tiled = get_tile_images(rgbir_image,(6,256,256))\n",
    "     \n",
    "        # write image chips\n",
    "        numtiles,numbands,rows,cols = rgbir_image_tiled.shape\n",
    "        rowOffset = 0\n",
    "        blockSize = int(math.sqrt(numtiles))\n",
    "        for tileIndexAlongY in range(0,blockSize):\n",
    "            tileULY = ULY + (tileIndexAlongY * cellSizeY * 256)\n",
    "            for tileIndexAlongX in range(0,blockSize):\n",
    "                tileULX = ULX + (tileIndexAlongX * cellSizeX * 256)\n",
    "                # print(str(tileULX)+\",\"+str(tileULY))\n",
    "                globalTileIndex = tileIndexAlongY + tileIndexAlongX + rowOffset\n",
    "                aTileImage = rgbir_image_tiled[globalTileIndex,:,:,:]\n",
    "                    \n",
    "                # aTileImage = np.expand_dims(aTileImage,0)\n",
    "                tileMetadata = inputMetadata.copy()\n",
    "                tileTransform = Affine(cellSizeX,\n",
    "                                   inputTransform.b,\n",
    "                                   tileULX,\n",
    "                                   inputTransform.d,\n",
    "                                   cellSizeY,\n",
    "                                   tileULY)\n",
    "                \n",
    "                #tileMetadata.update({'driver': 'GTiff',\n",
    "                #                 'dtype': 'float64',\n",
    "                #                 'count': 4,\n",
    "                #                 'height': 256,\n",
    "                #                 'width': 256,\n",
    "                #                 'transform': tileTransform,\n",
    "                #                 'nodata':0})\n",
    "                \n",
    "                # two more bands have been added                \n",
    "                tileMetadata.update({'driver': 'GTiff',\n",
    "                                 'dtype': 'float64',\n",
    "                                 'count': 6,\n",
    "                                 'height': 256,\n",
    "                                 'width': 256,\n",
    "                                 'transform': tileTransform,\n",
    "                                 'nodata':0})\n",
    "                \n",
    "                tileFileName = os.path.basename(rgb_image).replace(\".tif\",\"_\"+str(globalTileIndex).zfill(4)+\".tif\")\n",
    "                tileFullName = os.path.join(image_chips_dir, tileFileName)\n",
    "                with rasterio.open(tileFullName, 'w', **tileMetadata) as dest:\n",
    "                    dest.write(aTileImage)\n",
    "                \n",
    "                #now mask nodata areas in the image\n",
    "                maskDone = maskImage(tileFullName,allPolygons)\n",
    "                if (not maskDone):\n",
    "                    print(\"failed\")\n",
    "                    \n",
    "            rowOffset = rowOffset + (blockSize-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indices(image):\n",
    "    red = image[0,:,:]\n",
    "    green = image[1,:,:]\n",
    "    blue = image[2,:,:]\n",
    "    nir = image[3,:,:]   \n",
    "    \n",
    "    #print(image.shape)\n",
    "    red_diff = np.subtract(nir,red)\n",
    "    red_sum = np.add(nir,red)\n",
    "    ndvi = np.divide(red_diff,red_sum,out=np.zeros_like(red_diff), where=red_sum!=0)\n",
    "    #print(ndvi.shape)\n",
    "    \n",
    "    red_green_diff = np.subtract(green,nir)\n",
    "    red_green_sum = np.add(green,nir)\n",
    "    ndwi = np.divide(red_green_diff,red_green_sum,out=np.zeros_like(red_green_diff), where=red_green_sum!=0)\n",
    "\n",
    "    #print(ndwi.shape)\n",
    "    #new_image = np.dstack((image[0,:,:],image[1,:,:],image[2,:,:],image[3,:,:],ndvi,ndwi))\n",
    "    new_image = np.stack((image[0,:,:],image[1,:,:],image[2,:,:],image[3,:,:],ndvi,ndwi),axis=0)\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def maskImages(train_images_dir,labels_chips_dir, LU_LABELS):\n",
    "    for filename in os.listdir(train_images_dir):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            training_image_path = os.path.join(train_images_dir,filename)\n",
    "            #create a list of output ndarrays\n",
    "            mask_array = []\n",
    "            #iterate through the mask vectors\n",
    "            with rasterio.open(training_image_path) as src:\n",
    "                for LU_LABEL in LU_LABELS:\n",
    "                    masks = LU_LABELS[LU_LABEL]\n",
    "                    mask_image, mask_transform = rasterio.mask.mask(src,masks,nodata=0)\n",
    "                    mask_meta = src.meta.copy()\n",
    "                    mask_image[mask_image != 0] = LU_LABEL\n",
    "                    # only use the masked cells from blue band as its identical to others\n",
    "                    mask_array.append(mask_image[0]) \n",
    "            \n",
    "                #merge the masks into a single image\n",
    "                #by an element-wise maximum operator\n",
    "                #assumes that we dont have overlapping masks\n",
    "                final_mask = mask_array[0].copy()\n",
    "                for p in range(1,len(mask_array)):\n",
    "                    final_mask = np.maximum(final_mask,mask_array[p]).copy()\n",
    "\n",
    "                final_mask = final_mask.astype('uint8')\n",
    "                final_mask[final_mask < 1] = 0\n",
    "                \n",
    "                # skip this tile if it only has nodata otherwise\n",
    "                # we are overfeeding nodata\n",
    "                uniqueLabels = np.unique(final_mask)\n",
    "                if len(uniqueLabels) < 2 and uniqueLabels[0] ==0:\n",
    "                    continue\n",
    "                    \n",
    "                final_mask = np.expand_dims(final_mask, 0)\n",
    "\n",
    "#               plt.imshow(final_mask)\n",
    "#               plt.gray()\n",
    "#               plt.show()\n",
    "            \n",
    "                #save the final mask image\n",
    "                mask_meta.update({'driver': 'GTiff',\n",
    "                             'dtype': 'uint8',\n",
    "                             'count': 1,\n",
    "                             'height': final_mask.shape[1],\n",
    "                             'width': final_mask.shape[2],\n",
    "                             'transform': mask_transform,\n",
    "                             'nodata':0})\n",
    "                label_file_name = os.path.join(labels_chips_dir,filename.replace(\".tif\",\"_labels.tif\"))\n",
    "                with rasterio.open(label_file_name, 'w', **mask_meta) as dest:\n",
    "                    dest.write(final_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskImage(input_image_name,allPolygons):\n",
    "    try:\n",
    "        temp_file_name = input_image_name.replace(\".tif\",\"_temp.tif\")\n",
    "        maskDone = False\n",
    "        with rasterio.open(input_image_name) as src:\n",
    "            mask_image, mask_transform = rasterio.mask.mask(src,allPolygons,nodata=0)\n",
    "            mask_meta = src.meta.copy()            \n",
    "            # skip this tile if it only has nodata otherwise\n",
    "            # we are overfeeding nodata\n",
    "            uniqueLabels = np.unique(mask_image[0,:,:])\n",
    "            if len(uniqueLabels) < 2 and uniqueLabels[0] ==0:                \n",
    "                maskDone= input_image_name\n",
    "            else:\n",
    "                with rasterio.open(temp_file_name, 'w', **mask_meta) as dest:\n",
    "                    dest.write(mask_image)\n",
    "                    maskDone = temp_file_name\n",
    "        \n",
    "        if (maskDone == input_image_name):\n",
    "            os.remove(input_image_name)\n",
    "        elif (maskDone == temp_file_name):\n",
    "            os.remove(input_image_name)\n",
    "            os.rename(temp_file_name,input_image_name)\n",
    "        return True    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return maskDone\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(250,250))\n",
    "# columns = 4\n",
    "# rows = 4\n",
    "# tileIndex = 0\n",
    "# for i in range(1, columns*rows +1):\n",
    "#     bandIndex = math.ceil(i/4)-1  \n",
    "#     img = rgbir_image_tiled[i,3,:,:]\n",
    "#     fig.add_subplot(rows, columns, i)\n",
    "#     plt.imshow(img)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data polygons from landcover shapefile\n",
    "# open the landcover polygons and create an array of geometries for unique LU_LABELS\n",
    "def makeMasks(shapeFileName,labelFieldName):\n",
    "    LU_LABELS = {}\n",
    "    with fiona.open(shapeFileName, 'r') as landcovers:\n",
    "        for feature in landcovers:\n",
    "            LU_LABEL = feature['properties'][labelFieldName]\n",
    "            #geom = shape(feature[\"geometry\"]).buffer(-2.0) #  make a shapely object from the dict & negative buffer of 2m\n",
    "            #         clean = geom.buffer(0.0)\n",
    "            #         assert clean.geom_type == 'Polygon'\n",
    "            #         assert clean.is_valid\n",
    "            #         geom = clean    \n",
    "            #         feature[\"geometry\"] = mapping(geom) ## Make a dict from the shapely object.\n",
    "            landcover = feature[\"geometry\"]\n",
    "            if LU_LABEL in LU_LABELS:\n",
    "                oldArray = LU_LABELS[LU_LABEL]\n",
    "                oldArray.append(landcover)\n",
    "            else:\n",
    "                LU_LABELS[LU_LABEL] = [landcover]\n",
    "    return LU_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate all metrics\n",
    "def accuracy_statistics(true_class, predicted_class):\n",
    "   \n",
    "    # classification report\n",
    "    #target_names = [\"Class {}\".format(i) for i in range(3)]\n",
    "    print('Classification Report')\n",
    "    print(classification_report(true_class, predicted_class))\n",
    "   \n",
    "    # jaccard\n",
    "    print('Jaccard Score:')\n",
    "    print(jaccard_similarity_score(true_class, predicted_class))\n",
    "   \n",
    "    # confusion matrix\n",
    "    # plt.figure()\n",
    "    print ('Confusion Matrix')\n",
    "    #print(confusion_matrix(true_class, predicted_class))\n",
    "    cnf_matrix = confusion_matrix(true_class, predicted_class)\n",
    "\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['NoData', 'Solar Panel', 'Trees','Built Structure','Pond'],\n",
    "                          title='Confusion matrix, without normalization')\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['NoData', 'Solar Panel', 'Trees','Built Structure','Pond'], normalize=True,\n",
    "                          title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read land cover polygon  into geometry arrays that rasterio will use to create masks\n",
    "labels_shp = os.path.join(labels_dir, 'Labels4Classes_NoAugment.shp')\n",
    "LU_LABELS = makeMasks(labels_shp,'LU_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a global list of vectors for creating nodata area in RGB Images\n",
    "allPolygons = []\n",
    "for LU_LABEL in LU_LABELS:\n",
    "    allPolygons.extend(LU_LABELS[LU_LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the training RGB and CIR images to resample CIR, extract NIR band, \n",
    "# append NIR band to RGB, split into small tiles\n",
    "# create no data areas\n",
    "train_chips_dir = os.path.join(image_chips_dir, 'TRAIN')\n",
    "prepImages(ap_rgb_train_dir,ap_cir_train_dir,train_chips_dir,allPolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells to run after file export\n",
    "# using rasterio mask function to mask pixels using LU_LABEL in the training images\n",
    "train_images_dir = os.path.join(image_chips_dir,'TRAIN')\n",
    "train_labels_chips_dir = os.path.join(train_images_dir,'LABELS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskImages(train_images_dir,train_labels_chips_dir,LU_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the test RGB and CIR images to resample CIR, extract NIR band, append NIR band to RGB, split into small tiles\n",
    "test_chips_dir = os.path.join(image_chips_dir, 'TEST')\n",
    "prepImages(ap_rgb_test_dir,ap_cir_test_dir,test_chips_dir,allPolygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells to run after file export\n",
    "test_images_dir = os.path.join(image_chips_dir,'TEST')\n",
    "test_labels_chips_dir = os.path.join(test_images_dir,'LABELS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using rasterio mask function to mask pixels using LU_LABEL in the test images\n",
    "maskImages(test_images_dir,test_labels_chips_dir,LU_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "The last approach will implement Unet - a popular convolutional neural network for image classifcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to the training data\n",
    "image_chips = train_images_dir\n",
    "label_chips = train_labels_chips_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to store data and respective labels\n",
    "# imagese are split into halves..first half used for training, and remaining half into validation\n",
    "class train_data():\n",
    "    \n",
    "    def __init__(self, image, label):\n",
    "        self.image = []\n",
    "        self.label = []\n",
    "        for file in os.listdir(image):\n",
    "            if file.endswith(\".tif\"):\n",
    "                label_file= os.path.join(label,file.replace(\".tif\",\"_labels.tif\"))\n",
    "                self.image.append(io.imread(image+\"/\"+file,0))\n",
    "                self.label.append(io.imread(label_file,0))\n",
    "        \n",
    "#         for file in os.listdir(label):\n",
    "#             if file.endswith(\".tif\"):\n",
    "#                 self.label.append(io.imread(label+\"/\"+file,0))\n",
    "    \n",
    "    # training half\n",
    "    def get_image(self):\n",
    "        return np.array(self.image[:int(len(self.image)/2)])\n",
    "\n",
    "    def get_label(self):\n",
    "        return np.array(self.label[:int(len(self.image)/2)])\n",
    "    \n",
    "    # validation half\n",
    "    def get_validation_image(self):\n",
    "        return np.array(self.image[int(len(self.image)/2):])\n",
    "    \n",
    "    def get_validation_label(self):\n",
    "        return np.array(self.label[int(len(self.image)/2):])\n",
    "        \n",
    "    def set_image(self, new_images):\n",
    "        self.image = new_image\n",
    "    \n",
    "    def set_label(self,new_label):\n",
    "        self.label = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training data creation\n",
    "train_set = train_data(image_chips, label_chips)\n",
    "# to check the training data was correctly created, plot a random image tile\n",
    "#print (train_set.get_image()[99].shape)\n",
    "#show(train_set.get_image()[99][:,:,0])\n",
    "# to check the training data was correctly created, plot the associated labels\n",
    "#show(train_set.get_label()[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the training set\n",
    "train_images = train_set.get_image()\n",
    "train_labels = train_set.get_label()\n",
    "# access the validation set\n",
    "validation_images = train_set.get_validation_image()\n",
    "validation_labels = train_set.get_validation_label()\n",
    "# one hot encode the labels\n",
    "train_labels_encoded = to_categorical(train_labels, num_classes=5)\n",
    "validation_labels_encoded = to_categorical(validation_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that Keras expects the bands to be passed last - i.e. the data is shaped (256, 256, 12)\n",
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_zhixuhao(pretrained_weights = None,input_size = (256,256,6)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(5, (1, 1), activation = 'softmax')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Unet architecture\n",
    "def unet_cate(pretrained_weights = None,input_size = (256,256,6)):\n",
    "    # inputs = Input(shape=(256, 256, 4))\n",
    "    # two more bands have been added\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # use softmax in order to only output one class per pixel (unlike sigmoid which can have multiclass)\n",
    "    conv10 = Conv2D(5, (1, 1), activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    # see if a different loss and metrics can improve e.g. sorenson-dice\n",
    "    # model.compile(optimizer=Adam(lr=1e-9), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=Adam(lr=1e-9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # model.compile(optimizer=Adam(lr=1e-9), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 6)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 1760        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 32) 9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 256)  590080      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 256)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  524544      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  131200      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 32832       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 32) 8224        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 5)  165         conv2d_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,761,093\n",
      "Trainable params: 7,761,093\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 78 samples, validate on 78 samples\n",
      "Epoch 1/10\n",
      "78/78 [==============================] - 494s 6s/step - loss: 1.6091 - acc: 0.7174 - val_loss: 1.6093 - val_acc: 0.7568\n",
      "Epoch 2/10\n",
      "64/78 [=======================>......] - ETA: 45s - loss: 1.6091 - acc: 0.7384 "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model = unet_cate()\n",
    "model.fit(train_images, train_labels_encoded, validation_data=(validation_images, validation_labels_encoded), epochs=10,\n",
    "          batch_size=8, shuffle=True)\n",
    "# save the model and weights\n",
    "model_path = os.path.join(model_dir, '20181008_Unet_10epoch.h5')\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model(model_path)\n",
    "\n",
    "# lower the learning rate\n",
    "#lr = 0.000001\n",
    "#K.set_value(model.optimizer.lr, lr)\n",
    "\n",
    "#model.fit(train_images, train_label_encoded, validation_data=(validation_image, validation_label_encoded), epochs=10,\n",
    "#          batch_size=10, shuffle=True)\n",
    "#model_path = os.path.join(model_dir, '20180926_Unet_20epoch.h5')\n",
    "#model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model(model_path)\n",
    "\n",
    "# try increasing the learning rate as little improvement was seen in previous epochs\n",
    "#lr = 0.00001\n",
    "#K.set_value(model.optimizer.lr, lr)\n",
    "\n",
    "#model.fit(train_images, train_label_encoded, validation_data=(validation_image, validation_label_encoded), epochs=10,\n",
    "#          batch_size=8, shuffle=True)\n",
    "#model_path = os.path.join(model_dir, '20180905_Unet_30epoch.h5')\n",
    "#model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the latest trained model\n",
    "unet_model = load_model(model_path)\n",
    "\n",
    "# non custom load model syntax\n",
    "#unet_model = load_model(modelPath,custom_objects={'dice_coef_loss': dice_coef_loss,'dice_coef':dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_image_chips = test_images_dir \n",
    "test_label_chips = test_labels_chips_dir \n",
    "\n",
    "class test_data():\n",
    "    \n",
    "    def __init__(self, image, label):\n",
    "        self.image = []\n",
    "        self.label = []\n",
    "        self.filename = [] # store the filename because we can use it later to recreate the predicted image for it\n",
    "        \n",
    "        for file in os.listdir(image):\n",
    "            \n",
    "            if file.endswith(\".tif\"):\n",
    "                label_file= os.path.join(label,file.replace(\".tif\",\"_labels.tif\"))\n",
    "                self.image.append(io.imread(image+\"/\"+file,0))\n",
    "                self.label.append(io.imread(label_file,0))\n",
    "                self.filename.append(file)\n",
    "                \n",
    "#        for file in os.listdir(label):\n",
    "#            if file.endswith(\".tif\"):\n",
    "#                self.label.append(io.imread(label+\"/\"+file,0))\n",
    "               \n",
    "    def get_image(self):\n",
    "        return np.array(self.image[:int(len(self.image))])\n",
    "\n",
    "    def get_label(self):\n",
    "        return np.array(self.label[:int(len(self.image))])\n",
    "        \n",
    "    def set_image(self, new_images):\n",
    "        self.image = new_image\n",
    "    \n",
    "    def set_label(self,new_label):\n",
    "        self.label = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test set\n",
    "test_set = test_data(test_image_chips, test_label_chips)\n",
    "# access the test images and labels\n",
    "test_images = test_set.get_image()\n",
    "test_label = test_set.get_label()\n",
    "# one-hot-encode the labels\n",
    "test_label_encoded = to_categorical(test_label, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set using the trained model\n",
    "test_predict = unet_model.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode the predictions\n",
    "test_predict_decoded = np.argmax(test_predict, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate accuracy statistics\n",
    "accuracy_statistics(test_label.ravel(), test_predict_decoded.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(test_label.ravel(), test_predict_decoded.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing\n",
    "In order to generate coastline from the predicted regions, some post-processing is necessary to re-establish the order of the image tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the test_images, find the related predicted arrays, find the geotransformation of the test_image it came from\n",
    "# and the save the predicted array as an image using the geotransform\n",
    "for tileNum in range(len(test_predict_decoded)):\n",
    "    imgFileName = test_set.filename[tileNum]\n",
    "    imageFullName = os.path.join(test_image_chips,imgFileName)\n",
    "    with rasterio.open(imageFullName) as src:\n",
    "        out_transform = src.transform\n",
    "        out_meta = {'driver': 'GTiff',\n",
    "                    'dtype': 'uint8',\n",
    "                    'count': 1,\n",
    "                    'height': 256,\n",
    "                    'width': 256,\n",
    "                    'crs': src.crs,\n",
    "                    'transform': out_transform,\n",
    "                    'nodata':0}\n",
    "        predictionFileName = os.path.join(predictions_dir, 'UNET',imgFileName.replace(\".tif\",\"_prediction.tif\"))\n",
    "        with rasterio.open(predictionFileName, 'w', **out_meta) as dest:\n",
    "                    im_prediction = test_predict_decoded[tileNum,:,:]\n",
    "                    im_prediction = np.expand_dims(im_prediction, 0)\n",
    "                    im_prediction = im_prediction.astype('uint8')\n",
    "                    dest.write(im_prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
